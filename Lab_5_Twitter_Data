# Tweet reader starting point.
#
require (jsonlite)
library(tidyverse)
library(tidytext)
#
# Open input file. Use "r" for unzipped, "rb" for gzipped (this may
# not matter). gzfile() gives warnings on readLines() but seems to work.
# "fi" = "file input": "if" for "input file" would be a bad name.
#
fi <- file ("tweets.20130201_055232.10000lines", "r")

fo <- file("output.txt", "w") # Use stdout; replace with file name if needed
i <- 1
#
# Write out header. This is the only "write" without append=TRUE, so this
# command over-writes anything that was already in outfile.
#
cat ("ScreenName\tText\tLang\tDate\tTZ", "\n", sep = "\t", file = fo, append = TRUE)

while (i < 1000) {
  myline <- readLines (fi, 1)
  if (length (myline) == 0) # no line retrieved means EOF (end of file)
    break
  if (length (myline) == 1 && nchar (myline) == 0) # some lines are empty; skip 'em
    next 
  a <- try (txt <- fromJSON (myline))
  if (class (a) == "try-error") {
    cat ("Line", i, "was an error\n") # to stdout
    i <- i + 1
    next
  }
  if (names (txt)[1] == "delete") { # silently skip deletes for now
    ##      cat ("Line", i, "was a delete\n") # to stdout
    i <- i + 1
    next 
  }
  
  #Remove garbage
  txt$text <- gsub("http.*","",  txt$text)
  txt$text <- gsub("https.*","", txt$text)
  txt$text <- gsub("\t","",txt$text)
  txt$text <- gsub("\n","",txt$text)
  txt$text <- gsub("\r","",txt$text)
  
  
  #
  # Print out the text. The system should know if this is UTF-8.
  cat (txt$user$screen_name, txt$text, txt$lang, txt$created_at, txt$user$time_zone, "\n", file = fo, append = TRUE, sep = "\t")
  
  #
  # Tasks: (1) find the "created_at" date and convert it into a POSIX-style
  # date (object of class POSIXlt), possibly with strptime(); then convert
  # to text. (2) Find the "text" and make it printable. In particular, convert
  # new-lines, tabs, and carriage returns (\r) to something else. (3) Pull
  # out the language ("lang") and timezone ("time_zone") fields (the second one
  # might be missing). (4) Pull out coordinates, if supplied; if found, the
  # coordinates object contains a vector named "coordinates" with long and
  # lat.
  #
  i <- i + 1
}
close(fi)
close(fo)

#Clean data
twitter.data <- read.csv2("output.txt", sep = "\t")[,-6] %>% 
  tidyr::separate(Date, c(NA, "Month", "Day", "Time", NA, "Year"), sep = " ") %>% 
  tidyr::unite(Date, Month, Day, Year, Time, sep = " ") %>% 
  dplyr::filter(Text!="")
#Count number of english tweets
twitter.data %>% 
  dplyr::group_by(Lang) %>% 
  dplyr::summarise(Count = n())
#Plot number of Tweets in English
twitter.data %>% 
  ggplot2::ggplot(aes(x=Lang, fill = Lang)) + 
    geom_bar() +
    labs(title = "Tweets by Language", subtitle = "40% of Tweets are in English", x = "Language", y = "Count") +
    theme(legend.position = "none")
#Find number of US and Canadian Tweets
twitter.data %>% 
  dplyr::mutate(USorCA = ifelse(grepl("US | Canada", TZ), "Yes", "No")) %>% 
  dplyr::group_by(USorCA) %>% 
  dplyr::summarise(Count = n())
#Plot US and Canadian Tweets
twitter.data %>% 
  dplyr::mutate(USorCA = ifelse(grepl("US | Canada", TZ), "Yes", "No")) %>% 
  dplyr::group_by(USorCA) %>% 
  dplyr::summarise(Count = n()) %>% 
  ggplot2::ggplot(aes(x="", y=Count, fill=as.factor(USorCA))) + 
    geom_bar(width = 1, stat = "identity") + 
    coord_polar("y", start=0) +
    labs(title = "Proportion of Tweets that are from US or Canada", fill = "Are Tweets from US or CA",
       subtitle = "24% of Tweets are from US or CA") +
    theme_void()


#####Sentiment Analysis#####
tidytext::sentiments
twitter.data$Text <- as.character(twitter.data$Text)
# join sentiment classification to the tweet words
bing_word_counts <- twitter.data %>%
  dplyr::select(Text) %>% 
  tidytext::unnest_tokens(word, Text) %>% 
  dplyr::anti_join(stop_words) %>% 
  dplyr::inner_join(get_sentiments("bing")) %>%
  dplyr::count(word, sentiment, sort = TRUE) %>%
  dplyr::ungroup()

#plot the top positive and negative words
bing_word_counts %>%
  dplyr::group_by(sentiment) %>%
  dplyr::top_n(10) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(word = reorder(word, n)) %>%
  ggplot2::ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(title = "Sentiment of Tweets",
       y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
